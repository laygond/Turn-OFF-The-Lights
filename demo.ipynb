{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Install and Import Modules\n",
    "#### Install \n",
    "Add more if needed. I have provided some installation commands but you may need more if you do not have them installed yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# %%capture is used to ignore output when content is boring.\n",
    "# This is how you install modules from jupyter notebook instead of terminal. \n",
    "# Install the one you need or comment them out \n",
    "!pip3 install -U imageio-ffmpeg         #It contains VideoFileClip module needed in the next cell. \n",
    "!pip3 install ipywidgets                #It contains ipywidget module\n",
    "!pip install opencv-contrib-python      #It contains opencv module from https://www.pyimagesearch.com/2018/09/19/pip-install-opencv/\n",
    "!jupyter nbextension enable --py widgetsnbextension"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import\n",
    "if errors then you may need to go back and install it first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "import numpy as np\n",
    "import argparse\n",
    "import cv2\n",
    "import ipywidgets as ipw\n",
    "import os\n",
    "import random\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML, YouTubeVideo, display\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Watch Input <font color=\"violet\"> Video </font>\n",
    "\n",
    "Run the sample video I have provided first along with the whole tutorial, then\n",
    "\n",
    "Try your own video:\n",
    "- Place your video in the `Input_Video` folder\n",
    "- Change <b>ONLY</b> the `video_name` in the cell below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "video_name = \"sample.mp4\"\n",
    "input_video_path = os.path.join(\"Input_Video\", video_name)\n",
    "\n",
    "#Erase this!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "video_name_part = video_name.split(\".\")    # sample & mp4 has been split\n",
    "dest_path = os.path.join(\"Output_Video\", video_name_part[0] + \"_rotated.\" + video_name_part[1])\n",
    "input_video_path = dest_path\n",
    "\n",
    "# Watch Video\n",
    "display(HTML(\"\"\"\n",
    "            <video width=\"960\" height=\"540\" controls>\n",
    "              <source src=\"{0}\">\n",
    "            </video>\n",
    "            \"\"\".format(input_video_path)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Needs Rotation?\n",
    "I recorded my video with my phone in horizontal position. So I need to rotate it. Run the cells below if you also need rotation. Otherwise skip this section and go to next section: `Visualize and Explore video`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotateImage(image, angle):\n",
    "    \"\"\"\"\n",
    "    Performs a counter clockwise rotation of the angle specified. Set Angle to 90 to rotate left or -90 for right  \n",
    "    \"\"\"\n",
    "\n",
    "    (h, w) = image.shape[:2]        # get image height, width\n",
    "    cx, cy = int(w/2), int(h/2)     # calculate the center of the original image    \n",
    "\n",
    "    # Translate image center to the right before rotation\n",
    "    tx = cy-cx     #translate in x\n",
    "    ty = 0         #translate in y\n",
    "    M  = np.float32([[1,0,tx],[0,1,ty]])\n",
    "    image = cv2.warpAffine(image, M, (h,h))       # make square image (hxh)\n",
    "\n",
    "    # Perform the counter clockwise rotation holding at the center\n",
    "    center = (cy, cy)               # calculate new center of square image\n",
    "    scale  = 1.0                    # keep same dimension in image\n",
    "    M = cv2.getRotationMatrix2D(center, angle, scale)\n",
    "    image = cv2.warpAffine(image, M, (h, h))\n",
    "\n",
    "    # Translate image center to the top and crop bottom\n",
    "    tx = 0          #translate in x\n",
    "    ty = cx-cy      #translate in y\n",
    "    M  = np.float32([[1,0,tx],[0,1,ty]])\n",
    "    image = cv2.warpAffine(image, M, (h,w))       # this crops bottom as well\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's implemented on the first frame of the video to make sure everything looks okay. Set `angle` to 90 to rotate left or -90 for right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load video and Read frame\n",
    "cap = cv2.VideoCapture(input_video_path)\n",
    "cap.set(cv2.CAP_PROP_POS_FRAMES, 0) #First frame\n",
    "_, frame = cap.read() \n",
    "\n",
    "# Rotate to left\n",
    "angle = 90\n",
    "frame_rotated = rotateImage(frame , angle)\n",
    "\n",
    "# Display\n",
    "frame = cv2.cvtColor(frame,cv2.COLOR_BGR2RGB)\n",
    "frame_rotated = cv2.cvtColor(frame_rotated,cv2.COLOR_BGR2RGB)\n",
    "\n",
    "plt.figure(figsize=(11, 5))   #width, height in inches\n",
    "plt.subplot(1,2,1)\n",
    "plt.title(\"Original\")\n",
    "plt.imshow(frame)\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.title(\"Rotated\")\n",
    "plt.imshow(frame_rotated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It works! So let's implemented in the whole video and place it in the `Output_Video` folder which we will create. Again set `angle` to 90 to rotate left or -90 for right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create folder to place output videos at same level directory as input folder\n",
    "try:\n",
    "    os.mkdir(\"Output_Video\")\n",
    "except FileExistsError:\n",
    "    print (\"Output Folder is ready already\")\n",
    "    \n",
    "# Rotate video\n",
    "angle = 90\n",
    "clip  = VideoFileClip(input_video_path)\n",
    "video_clip = clip.fl_image(lambda image: rotateImage(image, angle))\n",
    "\n",
    "# Save rotated video \n",
    "video_name_part = video_name.split(\".\")    # sample & mp4 has been split\n",
    "dest_path = os.path.join(\"Output_Video\", video_name_part[0] + \"_rotated.\" + video_name_part[1])\n",
    "%time video_clip.write_videofile(dest_path, audio=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's watch it now! And reassign the input video path to our new rotated video!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reassign Input path to rotated video\n",
    "input_video_path = dest_path\n",
    "\n",
    "# Watch Video                                  \n",
    "HTML(\"\"\"\n",
    "    <video width=\"960\" height=\"540\" controls>\n",
    "      <source src=\"{0}\">\n",
    "    </video>\n",
    "    \"\"\".format(dest_path)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize and Explore Video\n",
    "Add the Frame number to a frame. Run the following cells, then feel free to adjust `font_scale`, `color`, and `thickness` according to your video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load video\n",
    "cap = cv2.VideoCapture(input_video_path)\n",
    "\n",
    "# Get General Info\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)      # OpenCV2 version 2 used \"CV_CAP_PROP_FPS\"\n",
    "frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "duration = int(frame_count/fps)\n",
    "\n",
    "# Read frame\n",
    "frame_num = random.randint(0,frame_count)\n",
    "cap.set(cv2.CAP_PROP_POS_FRAMES, frame_num)\n",
    "_,frame=cap.read()\n",
    "\n",
    "# Add frame number\n",
    "(h, w) = frame.shape[:2]                                                  # get image height, width\n",
    "box_startX, box_startY, box_endX, box_endY = 0, 0, int(0.5*w), int(0.2*h) # Box vertices follows golden ratio \n",
    "frame[box_startY: box_endY, box_startX:box_endX] = 0                      # Black rectangle in left corner \n",
    "text = \"Frame: \"+ str(frame_num) + \"/\" + str(frame_count)\n",
    "text_startX, text_startY, font_scale, color, thickness = 0, box_endY- int(box_endY*0.4),  2.5, (0, 255, 0), 10\n",
    "cv2.putText(frame, text, (text_startX, text_startY),cv2.FONT_HERSHEY_SIMPLEX, font_scale, color, thickness )\n",
    "\n",
    "# Display\n",
    "print('Frames Per Sec FPS = ' + str(fps))\n",
    "print('Number of Frames   = ' + str(frame_count))\n",
    "print('Duration [Sec]     = ' + str(duration))\n",
    "minutes = int(duration/60)\n",
    "seconds = duration%60\n",
    "print('Duration [Min:Sec] = ' + str(minutes) + ':' + str(seconds))\n",
    "frame = cv2.cvtColor(frame,cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(frame)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have decided what `font_scale`, `color`, and `thickness` suits your video. It is time to apply to all frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addFrameNumber(image, frame_num, frame_count, font_scale, color, thickness):\n",
    "    \n",
    "    # Add frame number\n",
    "    (h, w) = image.shape[:2]                                                  # get image height, width\n",
    "    box_startX, box_startY, box_endX, box_endY = 0, 0, int(0.5*w), int(0.2*h) # Box vertices follows golden ratio \n",
    "    image[box_startY: box_endY, box_startX:box_endX] = 0                      # Black rectangle in left corner \n",
    "    text = \"Frame: \"+ str(frame_num) + \"/\" + str(frame_count)\n",
    "    text_startX, text_startY = 0, box_endY- int(box_endY*0.4)\n",
    "    cv2.putText(image, text, (text_startX, text_startY),cv2.FONT_HERSHEY_SIMPLEX, font_scale, color, thickness)\n",
    "    \n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load video\n",
    "cap = cv2.VideoCapture(input_video_path)\n",
    "\n",
    "# Get General Info\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)      # OpenCV2 version 2 used \"CV_CAP_PROP_FPS\"\n",
    "frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "duration = int(frame_count/fps)\n",
    "\n",
    "# Read frame\n",
    "frame_num = random.randint(0,frame_count)\n",
    "cap.set(cv2.CAP_PROP_POS_FRAMES, frame_num)\n",
    "_,frame=cap.read()\n",
    "\n",
    "# Add frame number\n",
    "font_scale, color, thickness= 2.5, (0, 255, 0), 10\n",
    "frame = addFrameNumber(frame, frame_num, frame_count, font_scale, color, thickness)\n",
    "\n",
    "# Display\n",
    "print('Frames Per Sec FPS = ' + str(fps))\n",
    "print('Number of Frames   = ' + str(frame_count))\n",
    "print('Duration [Sec]     = ' + str(duration))\n",
    "minutes = int(duration/60)\n",
    "seconds = duration%60\n",
    "print('Duration [Min:Sec] = ' + str(minutes) + ':' + str(seconds))\n",
    "frame = cv2.cvtColor(frame,cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(frame)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cap.set(cv2.CAP_PROP_POS_FRAMES, frame_num)\n",
    "_,frame=cap.read()\n",
    "\n",
    "# Add frame number\n",
    "font_scale, color, thickness= 2.5, (0, 255, 0), 10\n",
    "frame = addFrameNumber(frame, frame_count, font_scale, color, thickness)\n",
    "\n",
    "# Display\n",
    "print('Frames Per Sec FPS = ' + str(fps))\n",
    "print('Number of Frames   = ' + str(frame_count))\n",
    "print('Duration [Sec]     = ' + str(duration))\n",
    "minutes = int(duration/60)\n",
    "seconds = duration%60\n",
    "print('Duration [Min:Sec] = ' + str(minutes) + ':' + str(seconds))\n",
    "frame = cv2.cvtColor(frame,cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(frame)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create folder to place output videos at same level directory as input folder\n",
    "try:\n",
    "    os.mkdir(\"Output_Video\")\n",
    "except FileExistsError:\n",
    "    print (\"Output Folder is ready already\")\n",
    "    \n",
    "# Add frame number in video\n",
    "font_scale, color, thickness= 2.5, (0, 255, 0), 10\n",
    "clip  = VideoFileClip(input_video_path)\n",
    "video_clip = clip.fl_image(lambda image: addFrameNumber(image, frame_count, font_scale, color, thickness))\n",
    "\n",
    "# Save rotated video \n",
    "video_name_part = video_name.split(\".\")    # sample & mp4 has been split\n",
    "dest_path = os.path.join(\"Output_Video\", video_name_part[0] + \"_withFrameNumbers.\" + video_name_part[1])\n",
    "%time video_clip.write_videofile(dest_path, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reassign Input path to rotated video\n",
    "input_video_path = dest_path\n",
    "\n",
    "# Watch Video                                  \n",
    "HTML(\"\"\"\n",
    "    <video width=\"960\" height=\"540\" controls>\n",
    "      <source src=\"{0}\">\n",
    "    </video>\n",
    "    \"\"\".format(dest_path)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "digits = datasets.load_digits()\n",
    "\n",
    "def browse_images(digits):\n",
    "    n = len(digits.images)\n",
    "    def view_image(i):\n",
    "        plt.imshow(digits.images[i], cmap=plt.cm.gray_r, interpolation='nearest')\n",
    "        plt.title('Training: %s' % digits.target[i])\n",
    "        plt.show()\n",
    "    ipw.interact(view_image, i=(0,n-1))\n",
    "\n",
    "browse_images(digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cap = cv2.VideoCapture(input_video_path)\n",
    "# cap.set(cv2.CAP_PROP_POS_FRAMES, 1009)\n",
    "# _,frame=cap.read()\n",
    "# frame = cv2.cvtColor(frame,cv2.COLOR_BGR2RGB)\n",
    "# plt.imshow(frame)\n",
    "# plt.show()\n",
    "\n",
    "def browse_images(cap):\n",
    "    n = frame_count#int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    def view_image(i):\n",
    "        \n",
    "        cap = cv2.VideoCapture(input_video_path)\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, i)\n",
    "        _,frame=cap.read()\n",
    "        frame = cv2.cvtColor(frame,cv2.COLOR_BGR2RGB)\n",
    "        plt.imshow(frame)\n",
    "        plt.show()\n",
    "    ipw.interact(view_image, i=(0,n-1))\n",
    "\n",
    "browse_images(cap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Youtube Video explaining about widgets\n",
    "#display (YouTubeVideo('eWzY2nGfkXk'))\n",
    "\n",
    "# Widgets\n",
    "right_btn  = ipw.Button( button_style='info', icon='fa-arrow-right' )\n",
    "left_btn   = ipw.Button( button_style='info', icon='fa-arrow-left') # 'fa-step-forward'\n",
    "slider     = ipw.IntSlider(value=0, min=0, max=frame_count-1, description='FRAME:', continuous_update=True)\n",
    "title      = ipw.HTML(\"<h3 class='text-left'><font color='green'> My Media Player</font> in <font color='blue'> Frames</font></h3>\")\n",
    "play       = ipw.Play(interval=10, min=0, max=frame_count-1, description=\"Press play\")\n",
    "video_out  = ipw.Output(layout={'border': '1px solid black'})\n",
    "#print(video_out.keys) # Check all input arguments\n",
    "\n",
    "# Linkers\n",
    "play_slider_link = ipw.jslink((play, 'value'), (slider, 'value'))\n",
    "\n",
    "\n",
    "# out.append_stdout('Output appended with append_stdout')\n",
    "# out.append_display_data(YouTubeVideo('eWzY2nGfkXk'))\n",
    "#     |\n",
    "\n",
    "#Callback functions\n",
    "plt.figure(figsize=(20, 20))   #width, height in inches\n",
    "def right_btn_callback(change):\n",
    "    slider.value = min(slider.value+1,slider.max)\n",
    "def left_btn_callback(change):\n",
    "    slider.value = max(slider.value-1,slider.min)\n",
    "def play_callback(change):\n",
    "    slider.value = play.value\n",
    "def slider_callback(change):\n",
    "    video_out.clear_output()\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, slider.value)\n",
    "    _,frame=cap.read()\n",
    "    frame = cv2.cvtColor(frame,cv2.COLOR_BGR2RGB)\n",
    "    with video_out:\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.imshow(frame)\n",
    "        display(plt.show())\n",
    "#     with video_out:\n",
    "#         display(plt.imshow(frame))\n",
    "#     video_out.append_display_data(frame)\n",
    "\n",
    "# Triggers        \n",
    "right_btn.on_click(right_btn_callback)\n",
    "left_btn.on_click(left_btn_callback)\n",
    "slider.observe(slider_callback, 'value')\n",
    "play.observe(play_callback, 'value')\n",
    "\n",
    "#Display\n",
    "media_player = ipw.VBox([title, video_out, ipw.HBox([play, left_btn, slider, right_btn])])\n",
    "display(media_player)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use this to discover what frame numbers we need to set the beginnings and ends of when we turn OFF the lights in the video.\n",
    "\n",
    "- [Widget List](https://ipywidgets.readthedocs.io/en/latest/examples/Widget%20List.html#Button)\n",
    "- [Widget_Tutorial](https://towardsdatascience.com/bring-your-jupyter-notebook-to-life-with-interactive-widgets-bc12e03f0916)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DisplayFrame():\n",
    "    # Read frame\n",
    "    _,frame=cap.read(0)\n",
    "    \n",
    "    # Display\n",
    "    frame = cv2.cvtColor(frame,cv2.COLOR_BGR2RGB)\n",
    "    plt.figure(figsize=(11, 5))   #width, height in inches\n",
    "    plt.title(\"Original\")\n",
    "    plt.imshow(frame)\n",
    "\n",
    "right.on_click(DisplayFrame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Play the video inline by running the following cell, or if you prefer find the video in your filesystem (should be in the same directory) and play it in your video player of choice.\n",
    "</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# When everything done, release the capture\n",
    "cap.release()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
