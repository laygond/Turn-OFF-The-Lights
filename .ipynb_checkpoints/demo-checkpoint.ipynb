{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# USAGE\n",
    "# py face_cropper_db_generator.py --input input_dataset --output db_cropped_faces --prototxt deploy.prototxt.txt --model res10_300x300_ssd_iter_140000.caffemodel\n",
    "\n",
    "# import the necessary packages\n",
    "import numpy as np\n",
    "import argparse\n",
    "import cv2\n",
    "import imutils\n",
    "from imutils import paths\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct the argument parse and parse the arguments\n",
    "ap = argparse.ArgumentParser()\n",
    "ap.add_argument(\"-i\", \"--input\", required= True,\n",
    "\thelp=\"path to input images\")\n",
    "ap.add_argument(\"-o\", \"--output\", required= True,\n",
    "\thelp=\"path to output cropped faces\")\n",
    "ap.add_argument(\"-p\", \"--prototxt\", required=True,\n",
    "\thelp=\"path to Caffe 'deploy' prototxt file\")\n",
    "ap.add_argument(\"-m\", \"--model\", required=True,\n",
    "\thelp=\"path to Caffe pre-trained model\")\n",
    "ap.add_argument(\"-c\", \"--confidence\", type=float, default=0.5,\n",
    "\thelp=\"minimum probability to filter weak detections\")\n",
    "ap.add_argument(\"-b\", \"--boxsizefactor\", type=float, default=0.25,\n",
    "\thelp=\"percentage increase in detected box size for creating independent pictures\")\n",
    "args = vars(ap.parse_args())\n",
    "\n",
    "# DEBUG MODE\n",
    "# args = {\"input\": \"friendsSA.jpg\",\n",
    "#         \"prototxt\": \"deploy.prototxt.txt\",\n",
    "#         \"model\": \"res10_300x300_ssd_iter_140000.caffemodel\",\n",
    "#         \"confidence\": 0.15}\n",
    "\n",
    "# load our serialized model from disk\n",
    "print(\"[INFO] loading model...\")\n",
    "net = cv2.dnn.readNetFromCaffe(args[\"prototxt\"], args[\"model\"])\n",
    "\n",
    "# grab the paths to the input images in our dataset\n",
    "print(\"[INFO] grabbing input images..\")\n",
    "imagePaths = list(paths.list_images(args[\"input\"]))\n",
    "\n",
    "# Parameters used inside while loop\n",
    "thrsh_c = args[\"confidence\"]    # confidence threshold level for bounding boxes (just a change of vaiable)\n",
    "count_faces = 0                 # keep count of all faces processed\n",
    "idx = 0                         # index for iterating through images in imagePaths\n",
    "\n",
    "while True:\n",
    "\n",
    "    # load the input image and construct an input blob for the image\n",
    "    # by resizing to a fixed 300x300 pixels and then normalizing it\n",
    "    image = cv2.imread(imagePaths[idx])\n",
    "    (h, w) = image.shape[:2]\n",
    "    if w >1000:\n",
    "        image = imutils.resize(image, width=1000)\n",
    "        (h, w) = image.shape[:2]\n",
    "    \n",
    "    original_img = image.copy() \n",
    "    blob = cv2.dnn.blobFromImage(cv2.resize(image, (300, 300)), 1.0,\n",
    "        (300, 300), (104.0, 177.0, 123.0))\n",
    "\n",
    "    # pass the blob through the network and obtain the detections and\n",
    "    # predictions\n",
    "    print(\"[INFO] computing object detections...\")\n",
    "    net.setInput(blob)\n",
    "    detections = net.forward()\n",
    "\n",
    "    # Store all bounding box coordinates per image and automatically reset for next image\n",
    "    startXList =[]\n",
    "    startYList =[]\n",
    "    endXList =[]\n",
    "    endYList =[]\n",
    "    \n",
    "    # loop over the detections\n",
    "    for i in range(0, detections.shape[2]):\n",
    "        # extract the confidence (i.e., probability) associated with the\n",
    "        # prediction\n",
    "        confidence = detections[0, 0, i, 2]\n",
    "\n",
    "        # filter out weak detections by ensuring the `confidence` is\n",
    "        # greater than the minimum confidence\n",
    "        if confidence > thrsh_c:\n",
    "            # compute the (x, y)-coordinates of the bounding box for the\n",
    "            # object and save them\n",
    "            box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])\n",
    "            (startX, startY, endX, endY) = box.astype(\"int\")\n",
    "\n",
    "            startXList.append(startX)\n",
    "            startYList.append(startY)\n",
    "            endXList.append(endX)\n",
    "            endYList.append(endY)\n",
    "    \n",
    "            # draw the bounding box of the face along with the associated\n",
    "            # probability\n",
    "            text = \"{:.2f}%\".format(confidence * 100)\n",
    "            y = startY - 10 if startY - 10 > 10 else startY + 10\n",
    "            cv2.rectangle(image, (startX, startY), (endX, endY),\n",
    "                (0, 0, 255), 2)\n",
    "            cv2.putText(image, text, (startX, y),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.45, (0, 0, 255), 2)\n",
    "\n",
    "    # show the output frame\n",
    "    cv2.imshow('Whole Detection', image)\n",
    "    key = cv2.waitKey(0) & 0xFF\n",
    "\n",
    "    # -------------KEYBOARD COMMANDS-------------------\n",
    "    # if `q` key was pressed, break from the loop\n",
    "    # if 'd' is pressed, repeat detection in image with lower threshold level (confidence) \n",
    "    # if 'i' is pressed, repeat detection in image with higher threshold level (confidence) \n",
    "    # if 'p' is pressed, go to previous image in input dataset   \n",
    "    # if 'n' is pressed, go to next image in input dataset  \n",
    "    # if 'c' is pressed, crop all detected faces in an image and save them as independent images at given directory     \n",
    "    \n",
    "    if key == ord(\"q\"):\n",
    "        break    \n",
    "    if key == ord(\"d\"):\n",
    "        thrsh_c = thrsh_c - .05 if thrsh_c - .05 >= 0 else thrsh_c\n",
    "        print(\"[INFO] Repeating Detection. Confidence Threshold Now: \", thrsh_c )\n",
    "    if key == ord(\"i\"):\n",
    "        thrsh_c = thrsh_c + .05 if thrsh_c + 0.05 <= 1 else thrsh_c\n",
    "        print(\"[INFO] Repeating Detection. Confidence Threshold Now: \", thrsh_c )     \n",
    "    if key == ord(\"p\"):\n",
    "        idx = idx - 1 if idx - 1 >= 0 else idx\n",
    "        print(\"[INFO] This is image: \", imagePaths[idx][-1])    \n",
    "    if key == ord(\"n\"):\n",
    "        idx = idx + 1 if idx + 1 < len(imagePaths) else idx\n",
    "        print(\"[INFO] This is image: \", imagePaths[idx][-1])   \n",
    "    if key == ord(\"c\"):\n",
    "        print(\"[INFO] Collecting detected faces as independent images\")\n",
    "        for i in range(len(startYList)):\n",
    "            delta_y = endYList[i] - startYList[i]\n",
    "            delta_x = endXList[i] - startXList[i] \n",
    "            top_y = startYList[i] - np.int((delta_y)*args[\"boxsizefactor\"])\n",
    "            bottom_y = endYList[i] + np.int((delta_y)*args[\"boxsizefactor\"])\n",
    "            left_x = startXList[i] - np.int((delta_x)*args[\"boxsizefactor\"])\n",
    "            right_x = endXList[i] + np.int((delta_x)*args[\"boxsizefactor\"])\n",
    "            if top_y < 0: top_y = 0  \n",
    "            if bottom_y > h: bottom_y = h  \n",
    "            if left_x < 0: left_x = 0  \n",
    "            if right_x > w: right_x = w  \n",
    "            \n",
    "            cropped_face = original_img [top_y : bottom_y, left_x : right_x]\n",
    "            p = os.path.sep.join([args[\"output\"], \"{}.png\".format(str(count_faces).zfill(5))])\n",
    "            cv2.imwrite(p, cropped_face)\n",
    "            count_faces = count_faces + 1\n",
    "\n",
    "# do a bit of cleanup\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
